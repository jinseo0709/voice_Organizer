require('dotenv').config();
const express = require('express');
const cors = require('cors');
const multer = require('multer');
const { SpeechClient } = require('@google-cloud/speech');
const { Storage } = require('@google-cloud/storage');
const admin = require('firebase-admin');
const ffmpeg = require('fluent-ffmpeg');
const fs = require('fs');
const path = require('path');
const os = require('os');

const app = express();
const PORT = process.env.PORT || 8080;

// í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
if (!process.env.GOOGLE_CLOUD_PROJECT) {
  console.warn('âš ï¸  GOOGLE_CLOUD_PROJECT í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
}
if (!process.env.FIREBASE_PROJECT_ID) {
  console.warn('âš ï¸  FIREBASE_PROJECT_ID í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
}

// CORS ì„¤ì • - í™˜ê²½ ë³€ìˆ˜ì—ì„œ í—ˆìš© ë„ë©”ì¸ ë¡œë“œ (ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ í—ˆìš©)
const allowedOrigins = process.env.ALLOWED_ORIGINS 
  ? process.env.ALLOWED_ORIGINS.split(',')
  : [
      'http://localhost:3000',
      'https://voice-organizer-app.web.app',
      'https://voice-organizer-app.firebaseapp.com',
      '*' // ëª¨ë“  ë„ë©”ì¸ í—ˆìš©
    ];

app.use(cors({
  origin: function (origin, callback) {
    // ëª¨ë“  ì¶œì²˜ í—ˆìš© (ê°œë°œ í™˜ê²½)
    callback(null, true);
  },
  credentials: true,
  optionsSuccessStatus: 200,
  methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
  allowedHeaders: ['Content-Type', 'Authorization', 'X-Requested-With']
}));

app.use(express.json({ limit: '50mb' }));

// Multer ì„¤ì • (ë©”ëª¨ë¦¬ ì €ìž¥)
const upload = multer({ 
  storage: multer.memoryStorage(),
  limits: { fileSize: 50 * 1024 * 1024 } // 50MB ì œí•œ
});

// GCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
let speechClient;
let storage;

try {
  const gcpConfig = {
    projectId: process.env.GOOGLE_CLOUD_PROJECT || 'voice-organizer-480015'
  };
  
  // ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ì´ ìžˆëŠ” ê²½ìš° ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
  if (process.env.GOOGLE_APPLICATION_CREDENTIALS) {
    gcpConfig.keyFilename = process.env.GOOGLE_APPLICATION_CREDENTIALS;
  }
  
  speechClient = new SpeechClient(gcpConfig);
  storage = new Storage(gcpConfig);
  
  console.log('âœ… GCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ - í”„ë¡œì íŠ¸:', gcpConfig.projectId);
} catch (error) {
  console.error('âŒ GCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
}

// Firebase Admin ì´ˆê¸°í™”
try {
  if (!admin.apps.length) {
    const firebaseConfig = {
      projectId: process.env.FIREBASE_PROJECT_ID || 'voice-organizer-480015',
      storageBucket: process.env.FIREBASE_STORAGE_BUCKET || 'voice-organizer-480015.firebasestorage.app'
    };
    
    // ì„œë¹„ìŠ¤ ê³„ì • í‚¤ê°€ ì„¤ì •ëœ ê²½ìš° credential ì¶”ê°€
    if (process.env.GOOGLE_APPLICATION_CREDENTIALS) {
      firebaseConfig.credential = admin.credential.applicationDefault();
    }
    
    admin.initializeApp(firebaseConfig);
  }
  console.log('âœ… Firebase Admin ì´ˆê¸°í™” ì™„ë£Œ - í”„ë¡œì íŠ¸:', process.env.FIREBASE_PROJECT_ID || 'voice-organizer-app');
} catch (error) {
  console.error('âŒ Firebase Admin ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
}

// í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
app.get('/health', (req, res) => {
  res.json({ 
    status: 'healthy', 
    timestamp: new Date().toISOString(),
    service: 'voice-organizer-server'
  });
});

// Speech-to-Text API ì—”ë“œí¬ì¸íŠ¸
app.post('/api/speech-to-text', upload.single('audio'), async (req, res) => {
  try {
    console.log('ðŸŽ¤ GCP ìŒì„± ì¸ì‹ ìš”ì²­ ì‹œìž‘...');
    
    if (!req.file) {
      return res.status(400).json({ 
        success: false, 
        error: 'ì˜¤ë””ì˜¤ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.' 
      });
    }

    const audioBuffer = req.file.buffer;
    const options = req.body.options ? JSON.parse(req.body.options) : {};
    
    console.log('ðŸ“Š ì˜¤ë””ì˜¤ ë¶„ì„:', {
      fileName: req.file.originalname,
      fileSize: audioBuffer.length,
      audioSizeKB: Math.round(audioBuffer.length / 1024),
      options
    });

    // íŒŒì¼ í¬ê¸° ê¸°ë°˜ ë©”ì†Œë“œ ì„ íƒ (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ìž„ê³„ê°’ ë¡œë“œ)
    const audioSizeKB = audioBuffer.length / 1024;
    const thresholdKB = parseInt(process.env.AUDIO_SIZE_THRESHOLD_KB) || 500;
    const isLongAudio = audioSizeKB > thresholdKB;
    
    console.log(`ðŸ”€ ${isLongAudio ? 'LongRunningRecognize' : 'Recognize'} ë°©ì‹ ì‚¬ìš© (${audioSizeKB.toFixed(0)}KB)`);

    let result;
    if (isLongAudio) {
      result = await transcribeLongAudio(audioBuffer, options);
    } else {
      result = await transcribeShortAudio(audioBuffer, options);
    }

    console.log('âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ:', {
      transcript: result.transcript.substring(0, 100) + (result.transcript.length > 100 ? '...' : ''),
      confidence: result.confidence
    });

    res.json({
      success: true,
      ...result
    });

  } catch (error) {
    console.error('âŒ ìŒì„± ì¸ì‹ ì˜¤ë¥˜:', error);
    res.status(500).json({
      success: false,
      error: error.message || 'ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
    });
  }
});

// ì˜¤ë””ì˜¤ í˜•ì‹ ê°ì§€
function detectAudioFormat(buffer) {
  const header = buffer.slice(0, 12).toString('hex');
  const headerStr = buffer.slice(0, 12).toString('ascii');

  console.log('ðŸ” ì˜¤ë””ì˜¤ í—¤ë” ë¶„ì„:', { hex: header, ascii: headerStr });

  // WebM í˜•ì‹: 1A 45 DF A3 (EBML header)
  if (header.startsWith('1a45dfa3')) {
    return 'WEBM_OPUS';
  }

  // OGG í˜•ì‹: OggS
  if (headerStr.startsWith('OggS')) {
    return 'OGG_OPUS';
  }

  // M4A/MP4 í˜•ì‹: ftyp (FFmpeg ë³€í™˜ í•„ìš”)
  if (header.includes('66747970') || headerStr.includes('ftyp')) {
    return 'M4A'; // M4AëŠ” ë³„ë„ ë³€í™˜ í•„ìš”
  }

  // WAV í˜•ì‹: RIFF
  if (headerStr.startsWith('RIFF')) {
    return 'LINEAR16';
  }

  // MP3 í˜•ì‹: ID3 ë˜ëŠ” FF FB
  if (headerStr.startsWith('ID3') || header.startsWith('fffb') || header.startsWith('fff3')) {
    return 'MP3';
  }

  // FLAC í˜•ì‹: fLaC
  if (headerStr.startsWith('fLaC')) {
    return 'FLAC';
  }

  return null; // ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹
}

// M4Aë¥¼ WAVë¡œ ë³€í™˜ (FFmpeg ì‚¬ìš©)
async function convertM4AtoWAV(inputBuffer) {
  return new Promise((resolve, reject) => {
    const tempDir = os.tmpdir();
    const inputPath = path.join(tempDir, `input-${Date.now()}.m4a`);
    const outputPath = path.join(tempDir, `output-${Date.now()}.wav`);

    console.log('ðŸ”„ M4A â†’ WAV ë³€í™˜ ì‹œìž‘...');
    console.log('ðŸ“ ìž„ì‹œ íŒŒì¼:', { inputPath, outputPath });

    // ìž…ë ¥ íŒŒì¼ ì €ìž¥
    fs.writeFileSync(inputPath, inputBuffer);

    ffmpeg(inputPath)
      .toFormat('wav')
      .audioCodec('pcm_s16le')
      .audioChannels(1)
      .audioFrequency(16000)
      .on('start', (commandLine) => {
        console.log('ðŸŽ¬ FFmpeg ëª…ë ¹:', commandLine);
      })
      .on('progress', (progress) => {
        console.log('â³ ë³€í™˜ ì§„í–‰ì¤‘:', progress.percent ? `${progress.percent.toFixed(1)}%` : 'processing...');
      })
      .on('end', () => {
        console.log('âœ… M4A â†’ WAV ë³€í™˜ ì™„ë£Œ');

        // ì¶œë ¥ íŒŒì¼ ì½ê¸°
        const outputBuffer = fs.readFileSync(outputPath);

        // ìž„ì‹œ íŒŒì¼ ì •ë¦¬
        try {
          fs.unlinkSync(inputPath);
          fs.unlinkSync(outputPath);
          console.log('ðŸ—‘ï¸ ìž„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ');
        } catch (cleanupError) {
          console.warn('âš ï¸ ìž„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨:', cleanupError.message);
        }

        resolve(outputBuffer);
      })
      .on('error', (err) => {
        console.error('âŒ FFmpeg ë³€í™˜ ì˜¤ë¥˜:', err.message);

        // ìž„ì‹œ íŒŒì¼ ì •ë¦¬
        try {
          if (fs.existsSync(inputPath)) fs.unlinkSync(inputPath);
          if (fs.existsSync(outputPath)) fs.unlinkSync(outputPath);
        } catch (cleanupError) {
          console.warn('âš ï¸ ìž„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨:', cleanupError.message);
        }

        reject(new Error(`ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨: ${err.message}`));
      })
      .save(outputPath);
  });
}

// ì§§ì€ ì˜¤ë””ì˜¤ ì²˜ë¦¬ (500KB ë¯¸ë§Œ)
async function transcribeShortAudio(audioBuffer, options = {}) {
  const {
    languageCode = process.env.SPEECH_API_LANGUAGE || 'ko-KR',
    enableAutomaticPunctuation = true,
    model = 'default'
  } = options;

  // ì˜¤ë””ì˜¤ í˜•ì‹ ê°ì§€
  const detectedFormat = detectAudioFormat(audioBuffer);
  console.log('ðŸŽµ ê°ì§€ëœ ì˜¤ë””ì˜¤ í˜•ì‹:', detectedFormat);

  // M4A í˜•ì‹ì´ë©´ WAVë¡œ ë³€í™˜
  let processedBuffer = audioBuffer;
  let finalEncoding = detectedFormat;

  if (detectedFormat === 'M4A') {
    console.log('ðŸ”„ M4A í˜•ì‹ ê°ì§€ - WAVë¡œ ë³€í™˜ í•„ìš”');
    try {
      processedBuffer = await convertM4AtoWAV(audioBuffer);
      finalEncoding = 'LINEAR16';
      console.log('âœ… WAV ë³€í™˜ ì™„ë£Œ, ë²„í¼ í¬ê¸°:', processedBuffer.length);
    } catch (convertError) {
      console.error('âŒ M4A ë³€í™˜ ì‹¤íŒ¨:', convertError.message);
      throw new Error(`M4A íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨: ${convertError.message}`);
    }
  }

  const audioContent = processedBuffer.toString('base64');

  // ê°ì§€ëœ í˜•ì‹ì— ë”°ë¼ ì¸ì½”ë”© ì„¤ì •
  let encodingConfigs;

  if (finalEncoding === 'LINEAR16') {
    // ë³€í™˜ëœ WAV ë˜ëŠ” ì›ë³¸ WAV
    encodingConfigs = [
      { encoding: 'LINEAR16', sampleRateHertz: 16000 },
    ];
  } else if (finalEncoding === 'MP3') {
    encodingConfigs = [
      { encoding: 'MP3', sampleRateHertz: 48000 },
      { encoding: 'MP3', sampleRateHertz: 44100 },
      { encoding: 'MP3', sampleRateHertz: 16000 },
    ];
  } else if (finalEncoding === 'FLAC') {
    encodingConfigs = [
      { encoding: 'FLAC', sampleRateHertz: 48000 },
      { encoding: 'FLAC', sampleRateHertz: 44100 },
      { encoding: 'FLAC', sampleRateHertz: 16000 },
    ];
  } else {
    // WebM ë˜ëŠ” OGG (ê¸°ë³¸ê°’)
    encodingConfigs = [
      { encoding: 'WEBM_OPUS', sampleRateHertz: 48000 },
      { encoding: 'OGG_OPUS', sampleRateHertz: 48000 },
    ];
  }

  let lastError = null;

  for (const config of encodingConfigs) {
    const request = {
      config: {
        encoding: config.encoding,
        sampleRateHertz: config.sampleRateHertz,
        languageCode: languageCode,
        enableAutomaticPunctuation: enableAutomaticPunctuation,
        model: model,
        audioChannelCount: 1,
      },
      audio: {
        content: audioContent,
      },
    };

    console.log(`ðŸ“¡ GCP Speech-to-Text í˜¸ì¶œ ì‹œë„: ${config.encoding} @ ${config.sampleRateHertz}Hz`);

    try {
      const [response] = await speechClient.recognize(request);

      // ê²°ê³¼ê°€ ìžˆëŠ”ì§€ í™•ì¸
      if (response && response.results && response.results.length > 0) {
        console.log(`âœ… ì„±ê³µ: ${config.encoding} @ ${config.sampleRateHertz}Hz`);
        console.log('ðŸ“¥ GCP ì‘ë‹µ:', JSON.stringify(response, null, 2));
        return parseRecognitionResult(response);
      } else {
        console.log(`âš ï¸ ${config.encoding} @ ${config.sampleRateHertz}Hz: ê²°ê³¼ ì—†ìŒ, ë‹¤ìŒ ì‹œë„...`);
        lastError = new Error('ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.');
      }
    } catch (error) {
      console.error(`âŒ ${config.encoding} @ ${config.sampleRateHertz}Hz ì‹¤íŒ¨:`, error.message);
      lastError = error;
    }
  }

  // ëª¨ë“  ì‹œë„ ì‹¤íŒ¨
  throw lastError || new Error('ëª¨ë“  ì¸ì½”ë”© ì‹œë„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
}

// ê¸´ ì˜¤ë””ì˜¤ ì²˜ë¦¬ (500KB ì´ìƒ) - Firebase Storage ì‚¬ìš©
async function transcribeLongAudio(audioBuffer, options = {}) {
  const {
    languageCode = process.env.SPEECH_API_LANGUAGE || 'ko-KR',
    enableAutomaticPunctuation = true,
    model = process.env.SPEECH_API_MODEL_LONG || 'latest_long'
  } = options;

  // ì˜¤ë””ì˜¤ í˜•ì‹ ê°ì§€ ë° M4A ë³€í™˜
  const detectedFormat = detectAudioFormat(audioBuffer);
  console.log('ðŸŽµ ê°ì§€ëœ ì˜¤ë””ì˜¤ í˜•ì‹ (Long):', detectedFormat);

  let processedBuffer = audioBuffer;
  let finalEncoding = 'WEBM_OPUS';
  let sampleRateHertz = 48000;
  let contentType = 'audio/webm';
  let fileExtension = 'webm';

  if (detectedFormat === 'M4A') {
    console.log('ðŸ”„ M4A í˜•ì‹ ê°ì§€ (Long) - WAVë¡œ ë³€í™˜ í•„ìš”');
    try {
      processedBuffer = await convertM4AtoWAV(audioBuffer);
      finalEncoding = 'LINEAR16';
      sampleRateHertz = 16000;
      contentType = 'audio/wav';
      fileExtension = 'wav';
      console.log('âœ… WAV ë³€í™˜ ì™„ë£Œ (Long), ë²„í¼ í¬ê¸°:', processedBuffer.length);
    } catch (convertError) {
      console.error('âŒ M4A ë³€í™˜ ì‹¤íŒ¨ (Long):', convertError.message);
      throw new Error(`M4A íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨: ${convertError.message}`);
    }
  } else if (detectedFormat === 'LINEAR16') {
    finalEncoding = 'LINEAR16';
    sampleRateHertz = 16000;
    contentType = 'audio/wav';
    fileExtension = 'wav';
  } else if (detectedFormat === 'MP3') {
    finalEncoding = 'MP3';
    sampleRateHertz = 44100;
    contentType = 'audio/mpeg';
    fileExtension = 'mp3';
  }

  // Firebase Storageì— ìž„ì‹œ íŒŒì¼ ì—…ë¡œë“œ
  const tempFileName = `temp-audio-${Date.now()}.${fileExtension}`;
  const bucket = admin.storage().bucket();
  const file = bucket.file(`temp-audio/${tempFileName}`);

  console.log('ðŸ“ Firebase Storageì— ì˜¤ë””ì˜¤ ì—…ë¡œë“œ ì¤‘...');
  await file.save(processedBuffer, {
    metadata: {
      contentType: contentType,
    },
  });

  const gcsUri = `gs://voice-organizer-480015.firebasestorage.app/temp-audio/${tempFileName}`;
  console.log('ðŸ“¡ ì—…ë¡œë“œ ì™„ë£Œ:', gcsUri);

  const request = {
    config: {
      encoding: finalEncoding,
      sampleRateHertz: sampleRateHertz,
      languageCode: languageCode,
      enableAutomaticPunctuation: enableAutomaticPunctuation,
      model: model,
      audioChannelCount: 1,
      useEnhanced: true,
    },
    audio: {
      uri: gcsUri,
    },
  };

  console.log('ðŸ“¡ GCP Speech-to-Text (LONG) API í˜¸ì¶œ...');
  const [operation] = await speechClient.longRunningRecognize(request);
  console.log('â³ ê¸´ ì˜¤ë””ì˜¤ ì¸ì‹ ì§„í–‰ ì¤‘...');
  
  const [response] = await operation.promise();
  
  // ìž„ì‹œ íŒŒì¼ ì‚­ì œ
  try {
    await file.delete();
    console.log('ðŸ—‘ï¸ ìž„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ');
  } catch (deleteError) {
    console.warn('âš ï¸ ìž„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨:', deleteError.message);
  }

  return parseRecognitionResult(response);
}

// ê³µí†µ ê²°ê³¼ íŒŒì‹±
function parseRecognitionResult(response) {
  console.log('ðŸ” ì‘ë‹µ íŒŒì‹± ì¤‘...');
  
  if (!response || !response.results || response.results.length === 0) {
    console.error('âŒ ë¹ˆ ì‘ë‹µ:', JSON.stringify(response, null, 2));
    throw new Error('ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì˜¤ë””ì˜¤ì— ëª…í™•í•œ ìŒì„±ì´ í¬í•¨ë˜ì–´ ìžˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.');
  }

  const result = response.results[0];
  if (!result.alternatives || result.alternatives.length === 0) {
    throw new Error('ìŒì„± ì¸ì‹ ëŒ€ì•ˆ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.');
  }

  const alternative = result.alternatives[0];
  if (!alternative.transcript) {
    throw new Error('ìŒì„± ì¸ì‹ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì˜¤ë””ì˜¤ í’ˆì§ˆì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
  }

  console.log('âœ… íŒŒì‹± ì™„ë£Œ:', alternative.transcript);

  return {
    transcript: alternative.transcript,
    confidence: alternative.confidence || 0,
    alternatives: result.alternatives.map(alt => ({
      transcript: alt.transcript || '',
      confidence: alt.confidence || 0
    }))
  };
}

// ì—ëŸ¬ í•¸ë“¤ë§
app.use((error, req, res, next) => {
  console.error('ì„œë²„ ì˜¤ë¥˜:', error);
  res.status(500).json({
    success: false,
    error: 'Internal server error'
  });
});

// ì„œë²„ ì‹œìž‘
app.listen(PORT, () => {
  console.log(`ðŸš€ Voice Organizer ì„œë²„ê°€ í¬íŠ¸ ${PORT}ì—ì„œ ì‹¤í–‰ ì¤‘ìž…ë‹ˆë‹¤.`);
  console.log(`ðŸ“ í—¬ìŠ¤ì²´í¬: http://localhost:${PORT}/health`);
  console.log(`ðŸŽ¤ Speech API: http://localhost:${PORT}/api/speech-to-text`);
});

// graceful shutdown
process.on('SIGTERM', () => {
  console.log('ì„œë²„ ì¢…ë£Œ ì¤‘...');
  process.exit(0);
});

process.on('SIGINT', () => {
  console.log('ì„œë²„ ì¢…ë£Œ ì¤‘...');
  process.exit(0);
});